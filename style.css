-- Create the flyway_schema_history table in the correct schema
CREATE TABLE IF NOT EXISTS "create.cop-project".flyway_schema_history (
    installed_rank INTEGER NOT NULL,
    version VARCHAR(50),
    description VARCHAR(200) NOT NULL,
    type VARCHAR(20) NOT NULL,
    script VARCHAR(1000) NOT NULL,
    checksum INTEGER,
    installed_by VARCHAR(100) NOT NULL,
    installed_on TIMESTAMP NOT NULL DEFAULT now(),
    execution_time INTEGER NOT NULL,
    success BOOLEAN NOT NULL,
    PRIMARY KEY (installed_rank)
);

-- Create baseline record
INSERT INTO "create.cop-project".flyway_schema_history (
    installed_rank, version, description, type, script, 
    checksum, installed_by, installed_on, execution_time, success
) VALUES (
    1, '1.35.0', 'Baseline from SonataWorkflow 1.35.0', 'BASELINE', '<< Baseline >>',
    NULL, current_user, NOW(), 0, true
);

-- Verify the table was created
SELECT * FROM "create.cop-project".flyway_schema_history;






SELECT 
    CASE 
        WHEN metadata->>'name' LIKE '11840_%' THEN 'service_account'
        WHEN metadata->>'name' LIKE '%sa' THEN 'support_user' 
        ELSE 'developer_user'
    END as user_type,
    COUNT(*) as count
FROM cds.user_entities
GROUP BY user_type;




Task ID	Cadence	Meaning	Purpose
run_ldap_user_refresh	PT6H	Every 6 Hours	Refreshes user data from LDAP/Active Directory
run_ldap_group_refresh	PT6H	Every 6 Hours	Refreshes group memberships from LDAP/AD
run_project_refresh	0 */4 * * *	Every 4 Hours (Cron syntax)	General catalog processing/entity refresh
run_csi_refresh	0 0 * * *	Daily at Midnight (Cron)	Custom Software Integration refresh
run_cluster_refresh	0 0 * * *	Daily at Midnight (Cron)	Your OpenShift/Kubernetes cluster refresh
run_update_request_status...	PT30M	Every 30 Minutes	Internal order management status updates




-- Entities with processing errors that haven't been updated in a long time
SELECT COUNT(*) 
FROM refresh_state 
WHERE errors IS NOT NULL 
  AND next_update_at < NOW() - INTERVAL '30 days'
  AND last_discovery_at < NOW() - INTERVAL '30 days';-- Find entities that haven't been attempted in a long time and are not scheduled for a future update.
SELECT COUNT(*), entity_id, status
FROM refresh_state
WHERE next_update_at < NOW() - INTERVAL '7 days'
  AND (last_discovery_at < NOW() - INTERVAL '7 days' OR last_discovery_at IS NULL)
GROUP BY entity_id, status;




-- DELETE entities with errors that are very old and not being processed
DELETE FROM refresh_state 
WHERE errors IS NOT NULL 
  AND next_update_at < NOW() - INTERVAL '30 days'
  AND last_discovery_at < NOW() - INTERVAL '30 days'
LIMIT 5000; -- Start with a small batch
