Hi [Developer Lead's Name]. Following up on the Backstage 1.39.0 upgrade plan.

1. Action on Custom Plugins:
We need to break down the "Upgrade Custom Plugins" epic into granular, actionable subtasks. Please create subtickets in Kira for each custom plugin, specifically covering:

Assessment: Check compatibility with 1.39.0.

Code Changes: Implement necessary fixes for breaking changes.

Testing: Validate functionality in the staging environment.
This breakdown is essential for us to track progress accurately, especially with the team's variable availability.

2. Engaging Scrum Master:
To ensure we are realistic about timelines and workload, I'm formally engaging Neeraj in his capacity as Scrum Master. [Neeraj, please tag him], based on the detailed subtask list, can you please help us assess:

The current capacity of the development team, considering known PTO.

A realistic timeline for completing these plugin upgrades.

Work assignment to ensure balanced load.

Let's discuss the initial list of subtasks in our next sync. Please let me know if you have any immediate blockers for creating this breakdown.








Team Update - Memory Leak Issue:

âœ… Temporary fix working: Increased memory to 4Gi is buying us time - OOM kills now happen every 2 days instead of daily

ðŸ”„ Action plan:

Off-hours restart: Setting up periodic rollout restarts during low traffic

QA replication: Created Jira subtask to reproduce the memory leak in QA environment

Alert check: @Bippin - can you verify which distribution list gets the OOM alerts? I didn't receive any notifications



SELECT 
    CASE 
        WHEN metadata->>'name' LIKE '11840_%' THEN 'service_account'
        WHEN metadata->>'name' LIKE '%sa' THEN 'support_user' 
        ELSE 'developer_user'
    END as user_type,
    COUNT(*) as count
FROM cds.user_entities
GROUP BY user_type;




Task ID	Cadence	Meaning	Purpose
run_ldap_user_refresh	PT6H	Every 6 Hours	Refreshes user data from LDAP/Active Directory
run_ldap_group_refresh	PT6H	Every 6 Hours	Refreshes group memberships from LDAP/AD
run_project_refresh	0 */4 * * *	Every 4 Hours (Cron syntax)	General catalog processing/entity refresh
run_csi_refresh	0 0 * * *	Daily at Midnight (Cron)	Custom Software Integration refresh
run_cluster_refresh	0 0 * * *	Daily at Midnight (Cron)	Your OpenShift/Kubernetes cluster refresh
run_update_request_status...	PT30M	Every 30 Minutes	Internal order management status updates




-- Entities with processing errors that haven't been updated in a long time
SELECT COUNT(*) 
FROM refresh_state 
WHERE errors IS NOT NULL 
  AND next_update_at < NOW() - INTERVAL '30 days'
  AND last_discovery_at < NOW() - INTERVAL '30 days';-- Find entities that haven't been attempted in a long time and are not scheduled for a future update.
SELECT COUNT(*), entity_id, status
FROM refresh_state
WHERE next_update_at < NOW() - INTERVAL '7 days'
  AND (last_discovery_at < NOW() - INTERVAL '7 days' OR last_discovery_at IS NULL)
GROUP BY entity_id, status;




-- DELETE entities with errors that are very old and not being processed
DELETE FROM refresh_state 
WHERE errors IS NOT NULL 
  AND next_update_at < NOW() - INTERVAL '30 days'
  AND last_discovery_at < NOW() - INTERVAL '30 days'
LIMIT 5000; -- Start with a small batch
